"""
離散一様分布の定義
確率変数Xがn個の値（ x1,x2,x3,…,xnx1,x2,x3,…,xn ）を同じ確率でとりうるとき、Xは離散一様分布に従う。

f(xi)=1/n
"""

# 便利なモジュールを一通りimportしておきます
import numpy as np
from numpy.random import randn

import pandas as pd
from math import exp
from math import factorial
from IPython.display import Image


from scipy import stats
from scipy.stats import randint
from scipy.stats import uniform
# 組み合わせを求めるため
import scipy.misc as sc
from scipy.stats import binom
from scipy.stats import poisson
# scipy.statsの中にt分布があります。
from scipy.stats import t
import scipy.stats as ss


import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns


"""
仮想的なサイコロをつくって、その振る舞いを可視化してみます。
"""

# 確率質量関数（Probability Mass function）をつくって描画します。

# サイコロの取り得る値
roll_options = [1, 2, 3, 4, 5, 6]
# 確率の総和は1です。
tprod = 1
# 公正なサイコロだったら、どの目も同じ確率で出ます。

prod_roll = tprod / len(roll_options)
# 描画してみます。
[prod_roll]
uni_plot = plt.bar(roll_options, [prod_roll] * 6)

"""

平均と分散

平均は最大値（b）と最小値（a）を足して2で割ったものです。

μ=(b+a)/2

分散は次の式で計算できます。

σ2=(b−a+1)^2−1 / 12

Scipyを使うと、この分布を簡単に作る事ができます。
"""

# 最大の手前までなので、7です。
low, high = 1, 7

# このコードで、離散一様分布の平均と分散を計算できます。
mean, var = randint.stats(low, high)
print('平均= {} 分散={}'.format(mean, var))

# 確率質量関数（Probably Mass Function）も簡単です。
plt.bar(roll_options, randint.pmf(roll_options, low, high))

"""

German Tank Problem
離散一様分布の応用例としては、第2次世界大戦において、イギリスがドイツ軍の戦車の生産台数を推定したGerman Tank Problemが有名です。

Wikipedia（英語） http://en.wikipedia.org/wiki/German_tank_problem

詳しい解説はWikipediaの記事を読んでいただくことにして、簡単例を実際に計算してみましょう。

Population max = sample max + (sample max / sample size) − 1


5台（sample size)の戦車を捕らえ、それぞれのシリアル番号が、3,7,11,16だとすると、sample max=16になります。
最小分散不偏推定量を求めてみます。
"""

tank_estimate = 16 + (16 / 5) - 1
tank_estimate

# ベイズ統計的なアプローチでは、次のような値になります。

m = 16
k = 5
tank_b_estimate = (m - 1) * ((k - 1) / (k - 2))
tank_b_estimate


###############################################################################


"""
連続一様分布について解説します。離散一様分布を先に見ておいてください。
離散一様分布では、取り得る値と確率を分かりやすく対応付けることができました。
しかし、連続一様分布ではそうは行きません。無限の精度を求めると、いくらでも数字を細かくできます。
これは、2つの数字を考えたとき、その間から必ず別の数字を選べるという意味でもあります。
例えば、5.41と5.42を考えると、5.415を選べます。

そう考えると、連続一様分布では、取り得る値の個数nが無限大になります。そうなると、
確率は1/∞になってしまうので、0です。これでは話が始まりませんので、連続分布で確率を考えるときは、
1点ではなく、領域を考えます。これを分かり易くするために、例を交えながら、
さらに見ていくことにしましょう。

連続な確率変数Xが次のような確率密度関数（probability density function）に従うとき、
これを連続一様分布と呼びます。

f(x)=1 / (b−a)
a<=x<=b

離散一様分布では、f(x)=1/n でしたが、連続一様分布では、
最小値aと最大値bの間で定義される領域を考えます。

分布の平均は単純です。

(a+b) / 2

分散は次のように定義されます。

σ^2 = (b−a)^2 / 12

ニューヨーク市での平均的なタクシーの乗車時間は22分くらいであることが知られています。
調査の結果、この乗車時間が、19分から27分の間の連続的な一様分布に従うことが分かったとします。
タクシー乗車時間の確率密度関数を求めてみましょう。
"""


# 乗車時間の下限
a = 19

# 上限
b = 27

# 連続一様分布の確率密度関数です。
fx = 1.0 / (b - a)

print('確率密度関数は、{}'.format(fx))

# 分散
var = ((b - a)**2) / 12

print('分散={}'.format(var))

"""
乗車時間が少なくとも25分続く確率を計算してみましょう。
"""

# これは、全体から、乗車時間が25分より短い場合を引けばよいので、次のようにして求めることができます。

# 乗車時間が27分までに収まる確率は全体なので1です。
# 一方、乗車時間が25分までに収まる確率は、
f25 = (25 - 19) / (b - a)

ans = 1 - f25

print('乗車時間が少なくとも25分かかる確率は{}%'.format(100 * ans))

"""
scipyを使って便利に連続一様分布を作ってみます。


"""

# 最小と最大を作ります。
A = 0
B = 5

# AからBまで100ポイントを作っておきます。
x = np.linspace(A, B, 100)

# 連続一様分布は、uniform(loc=start point,scale=endpoint)で作れます。
rv = uniform(loc=A, scale=B)

# 確率密度関数（PDF）と累積分布関数（Cumulative Distribution Function)を描いてみます。
plt.plot(x, rv.pdf(x))
plt.plot(x, rv.cdf(x))

"""

青い線は、0.2のところにありますが、1/(5-0) が 1/5 で 0.2なので、すぐに確かめられます。

2,3は英語ですが、Web上にも有用な情報があります。
1.)https://ja.wikipedia.org/wiki/%E9%80%A3%E7%B6%9A%E4%B8%80%E6%A7%98%E5%88%86%E5%B8%83

2.)http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.uniform.html

3.)http://mathworld.wolfram.com/UniformDistribution.html
"""


###############################################################################


"""
二項分布（Binomial distribution）は離散分布の一種です
まずは例題

プレイヤーAとプレイヤーBの2人が、バスケットボールをします。Aは1ゲームで平均11回シュートをして、
平均的な成功率は72％です。一方、Bは15回シュートをしますが、平均的に48%しか決まりません。

問1: プレイヤーAが平均的な1試合で6回シュートを決める確率は？

問2: おなじく、プレイヤーBが1試合で6回シュートを決める確率は？

以下の条件が満たされれば、この問題を二項分布を使って考える事ができます。

1.) 全体がn回の連続した試行からなる
2.) それぞれの試行は、相互に排他的な2つの事象からなる（例えば成功と失敗）
3.) 成功の確率がpならば、失敗の確率は1-p
4.) それぞれの試行は独立
二項分布の確率質量関数は、以下のようになります。

Pr (X=k) = C(n,k) * p^k * (1−p)^n−k


nは試行の回数、kは成功の数、pは成功の確率、1-pは失敗の確率ですが、しばしばqと書かれます。

n回試行して、k回成功する確率は、

p^k

また、n-k回失敗する確率は

(1−p)^n−k

n回の試行で、k回の成功がどこにくるかわかりませんが、この並べ方は

C(n,k)

通りあります。 これらをすべて掛け合わせれば、n回中k回成功する確率が求まるわけです。

C(n,k) は組み合わせです。実際の計算は次のような式で表現できます。

C(n,k) = n! / k!(n−k)!

例題を解いてみましょう¶
"""

# Aの成功率
p_A = .72
# シュートの数
n_A = 11

# 成功数
k = 6


comb_A = sc.comb(n_A, k)

# これらを掛け合わせれば、確率がでます。
answer_A = comb_A * (p_A**k) * ((1 - p_A)**(n_A - k))

# パーセントで結果を格納しておきます。
answer_A = 100 * answer_A

# Bも同様の計算ができます。
p_B = .48
n_B = 15
comb_B = sc.comb(n_B, k)
answer_B = 100 * comb_B * (p_B**k) * ((1 - p_B)**(n_B - k))

print('プレイヤーAが平均的な試合で6回シュートを決める確率は{:0.2f}% '.format(answer_A))
print('')
print('プレイヤーBが平均的な試合で6回シュートを決める確率は{:0.2f}%'.format(answer_B))


"""
下手なシュートも数打ちゃあたる、ようにみえます。

では次に、9回決める確率を計算してみましょう。
"""
# 9回決めなければなりません。
k = 9

comb_A = sc.comb(n_A, k)
comb_B = sc.comb(n_B, k)

# 掛け合わせます。
answer_A = 100 * comb_A * (p_A**k) * ((1 - p_A)**(n_A - k))
answer_B = 100 * comb_B * (p_B**k) * ((1 - p_B)**(n_B - k))

print('プレイヤーAが平均的な試合で9回シュートを決める確率は{:0.2f}% '.format(answer_A))
print('')
print('プレイヤーBが平均的な試合で9回シュートを決める確率は{:0.2f}%'.format(answer_B))

"""

9回決める確率が高いのは、やはり上手なAのほうです。 ここで注意しなければいけないのは、
いま考えて居るのは、9回決める確率であって、少なくとも9回決める確率ではないということです。

平均と分散
二項分布の平均は単純です。

μ = n ∗ p

これは直感的にもわかりやすいでしょう。平均的な成功率と試行の回数を掛ければ平均的な成功の回数になります。

標準偏差（分散の平方根）は次の式で求められます。
     ______
σ = √n ∗ (1-p) ∗ p


シュートが決まる回数の平均と、+/- 標準偏差を計算できます。
"""

# 平均値です。
mu_A = n_A * p_A
mu_B = n_B * p_B

# 標準偏差を計算しましょう。
sigma_A = (n_A * p_A * (1 - p_A))**0.5
sigma_B = (n_B * p_B * (1 - p_B))**0.5

print('プレイヤーAは1試合で、平均{:0.1f}回±{:0.1f}シュートを決めます。'.format(mu_A, sigma_A))
print('\n')
print('プレイヤーBは1試合で、平均{:0.1f}回±{:0.1f}シュートを決めます。'.format(mu_B, sigma_B))
"""
scipyを利用できます
"""

mean, var = binom.stats(n_A, p_A)

print(mean)
print(var**0.5)


"""
確率質量関数も求められます
コインを10回投げて裏と表を出すことを考えてみましょう。
"""

# 10回と、表の確率0.5をセットします。
n = 10
p = 0.5

x = range(n + 1)

# 二項分布の確率質量関数をから、実際の確率を計算できます。
Y = binom.pmf(x, n, p)

Y

# プロットします。
plt.plot(x, Y, 'o')

# y=1.08はタイトルが少し上に行くようにするためです。
plt.title('Binomial Distribution PMF: 10 coin Flips, Odds of Success for Heads is p=0.5', y=1.08)

# 軸にもタイトルが付けられます。
plt.xlabel('Number of Heads')
plt.ylabel('Probability')
"""

2,3は英語ですが、Web上にも情報がありますので、参考にしてみてください。

1.) https://ja.wikipedia.org/wiki/%E4%BA%8C%E9%A0%85%E5%88%86%E5%B8%83

2.) http://stattrek.com/probability-distributions/binomial.aspx

3.) http://mathworld.wolfram.com/BinomialDistribution.html

"""

##############################################################################


"""
ポアソン分布とは？¶
ポアソン分布は、ある間隔（時間や長さなど）の間に起こるイベントの回数に注目するものです。
まずは、その定義をみたあとに、その式の意味するところを噛み砕いていくことにしましょう。

離散確率変数Xが、パラメータλを持つポアソン分布に従うとき、k=0,1,2..,
に対応する確率を生成する確率質量関数は、次の式で与えられます。

Pr (X=k) = λ^k * e^−λ / k!

eは自然対数の底（ネイピア数）で、e=2.718...となる数です。k!はkの階乗。

ポアソン分布には、次のような性質があります。

1.) 離散的です。(x=0,1,2,3...)
2.) この数は、0から無限大までの値を取り得ます。
3.) あまり頻繁には起こらない事象の確率分布を表現します。
4.) それぞれの事象は独立です。
5.) 時間や距離などの間隔で起きる事象について記述します。
6.) 事象が起きる回数の期待値は定数です。
例を見てみましょう。

マクドナルドのランチのピークは、12:30から1:00の間です。これまでの経験から、
平均で10人のお客さんが、この時間帯に来店することが分かっています。それでは、
ちょうど7人のお客さんが来店する確率はどれくらいでしょうか？また、
10人より多いお客さんが来る確率はどれくらいでしょうか？

これまでの経験から、お昼のピーク30分間に、10人のお客さんが来ることがわかっています。
この10は平均値、つまり期待値です。これはポアソン分布のパラメータλに相当します。

ポアソン分布はλが決まれば、決まりますので、この例題に答えることができます。やってみましょう。
"""

# 残念ながら、lambdaはPythonでは予約語なので、そのまま変数名には使えます。

# lambとして、λをセットします。
lamb = 10

# ちょうど7人来る確率を計算したいので、k=7です。
k = 7

# 確率質量関数をつかって確率を計算します。
prob = (lamb**k) * exp(-lamb) / factorial(k)

print(' 昼のピーク時にお客さんが7人である確率は、{:0.2f}%です。'.format(100 * prob))

"""
確率質量関数を手作りできました。scipyを使うともう少し楽です。
"""

# 平均は10です。
mu = 10

# 平均と分散を計算できます。
mean, var = poisson.stats(mu)

# 確率質量関数を使って、特定の確率を計算することも可能です。
odds_seven = poisson.pmf(7, mu)

print('ピーク時に7人の確率は{:0.2f}％'.format(odds_seven * 100))

print('平均={}'.format(mean))
"""
ピーク時に7人の確率は9.01％
平均=10.0
分布の全体を見ておくことにします。これは、10人よりお客が多い確率を求めるのに必要です。
"""


# 確率質量関数をプロットしてみましょう。

# ひとまず、30人のお客さんが来る確率です。理論的には無限大まであり得ます。
k = np.arange(30)

# 平均は10です。
lamb = 10

# これで確率を計算できます。
pmf_pois = poisson.pmf(k, lamb)
pmf_pois
plt.bar(k, pmf_pois)

"""

10人より多くのお客さんがくる確率はどれくらいでしょうか？

これは、11人以降の確率の値をすべて足し合わせれば良いわけですが、
これを実現するのが、累積分布関数（CDF: Cumulative Distribution Function）です。

累積分布関数は、指定された値までの確率を足し合わせた値を返してくれます。
"""


# お客さんが10人までの確率を計算するので、k = 10です。平均値もおなじく10
k, mu = 10, 10

# お客さんが10人までの確率を次のコードで計算できます。
prob_up_to_ten = poisson.cdf(k, mu)

print('お客さんが10人までの確率は、{:0.2f}%です。'.format(100 * prob_up_to_ten))

"""
お客さんが10人までの確率は、58.30%です。
10により多く来る確率は、1からこの値を引くだけです。
"""

prob_more_than_ten = 1 - prob_up_to_ten

print('10人より多くのお客さんが来る確率は、{:0.2f}%です。'.format(100 * prob_more_than_ten))

"""
10人より多くのお客さんが来る確率は、41.70%です。
ポアソン分布の基本的なことを解説しました。 以下の資料も参考にしてみてください。

1.)https://ja.wikipedia.org/wiki/%E3%83%9D%E3%82%A2%E3%82%BD%E3%83%B3%E5%88%86%E5%B8%83

2.)http://stattrek.com/probability-distributions/poisson.aspx

3.)http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.poisson.html
"""


"""
正規分布とは？¶
正規分布の確率密度関数は次の式で定義されます。
                       __
f( x | μ,σ ) = { 1 / σ√2π  } * e^−{ (x−μ)^2 / 2σ2 }


μは平均、σは標準偏差です。円周率π=3.14... と自然対数の底 e=2.718... は定数です。
確率の総和は1です。X=aとX=b（a<b）の間に挟まれた領域は、Xがaとbのあいだになる確率を
意味していて、これを次のように書きます。

分布の形を見て、正規分布の主な特徴を確認していきましょう。

1.) 左右に裾野を持ちます。
2.) 曲線は左右対称です。
3.) ピークは平均の値です。
4.) 標準偏差が曲線の形を特徴付けます。
    - 背が高い分布は、小さな標準偏差のときです。
    - 太った分布は、大きな標準偏差のときです。
5.) 曲線のしたの面積（AUC: area under the curve）は1です。
6.) 平均値、中央値、最頻値（mode）がすべて同じです。
平均が0、標準偏差が1の標準正規分布では、±1標準偏差に68%、±2標準偏差に95%が含まれ、
±3標準偏差までには、全体の99.7%が含まれます。この1,2,3といった数字をz-scoreと呼ぶこともあります。
"""

Image(url='http://upload.wikimedia.org/wikipedia/commons/thumb/2/25/The_Normal_Distribution.svg/725px-The_Normal_Distribution.svg.png')

"""
scipyを使って、正規分布を作ってみましょう。

"""

# 平均を0
mean = 0

# 標準偏差を1にしてみましょう。
std = 1

# 便宜的に領域を決めます。
X = np.arange(-4, 4, 0.01)

# 値を計算します。
Y = stats.norm.pdf(X, mean, std)

plt.plot(X, Y)

mu, sigma = 0, 0.1

# 正規分布に従う乱数を1000個生成します。
norm_set = np.random.normal(mu, sigma, 1000)
plt.hist(norm_set, bins=50)

"""

正規分布は非常に重要な分布なので、多くの情報があります。ここでの導入は、
最初の1歩にすぎませんので、是非いろいろと調べてみてください。

1.) https://ja.wikipedia.org/wiki/%E6%AD%A3%E8%A6%8F%E5%88%86%E5%B8%83

2.) http://mathworld.wolfram.com/NormalDistribution.html

3.) http://stattrek.com/probability-distributions/normal.aspx
"""


###############################################################################

"""

標本とは？

標本抽出（Sampling）とは、母集団と標本のあいだにある関係を説明するためのものです。
例えばアメリカ国民全体を対象に、何か調査をするのは難しいですが、その中から、
1000人だけを選んでアンケートを実施することは可能です。これが、母集団と標本の関係です。

標本抽出については、いろいろと興味深いことが沢山あります。たとえば、2つの標本の平均が違うとき、
それが偶然なのか、統計的に有意な差なのか、こういった疑問に統計学は一定の答えを与えてくれますが、
それはまた、別のレクチャーに回すとしましょう。

無作為抽出と乱数
標本は、母集団の性質を引き継いでいる必要があります。これを実現する最も基本的な方法に、
無作為抽出（random sampling）という方法があります。これは、
母集団から等確率にサンプルを抽出する方法です。箱に入ったいくつかのボールなど、
実体があれば良いですが、コンピュータを使って仮想的に行う場合は、乱数が必要になります。
コンピュータは、本当にランダムな数字を生成することは出来ませんので、
ランダムに見える数字を作る必要があります。これは疑似乱数と呼ばれ、様々な方法論がありますが、
Pythonをはじめ多くの現代的なライブラリでは、メルセンヌ・ツイスタ法（Mersenne Twister）
が使われています。


復元抽出と非復元抽出
非復元抽出（sampling without replacement）は、抽出したらそれを母集団にもどしません。
これはつまり、有限な標本を意味します。一方、復元抽出（sampling with replacement）は、
抽出したものを母集団に戻すイメージなので、無限です。たとえば、コイントスを考えます。
裏か表がでますが、やり続ける限り、それに応じて大きな標本を得ることができます。



標本分布の平均
Np個の母集団から、N個のサンプルを抽出したとします。ここで、Np>N です。このとき、
N個の値の平均値という新しい確率変数xを考えます。このxの平均と、標準偏差は、
母集団の平均と標準偏差を使って、次のように書くことができます。

平均:
μx = μ


標準偏差:
          _
σx = σ / √N

これは、標本の統計量から、母集団の統計量を推し量ることができることを意味します。
Nを大きくすればするほど、xの分散は小さくなるので、正確な平均値を知ることが出来るわけです。

比率の標本分布
成功確率p（失敗はq=1-p）で表現される母集団からの標本を考えます。確率pで1が、
確率qで0が返ってくると考えると分かり易いかも知れません。N個のサンプルの平均という新しい
確率変数を考えると、この平均と標準偏差は、次のように書くことができます。

平均:

μp = p

標準偏差:
      ______    ___________
σp = √pq / N = √p(1−p) / N

標本の差と和
正規分布に従う2つの母集団 N1とN2があるとします。これらの母集団からの標本について、
その差と和を考えて見ます。 S1をN1の統計量、S2をN2の統計量とすると、次の関係が成り立ちます。

差の統計量については、

平均:

μ S1−S2 = μS1 − μS2

標準偏差:
           _____________
σ S1−S2 = √σS1^2 + σs2^2

和の統計量については、

平均:

μ S1+S2 = μS1 + μS2

標準偏差:
           _____________
σ S1−S2 = √σS1^2 + σs2^2

平均は分かり易いですが、標準偏差はどちらもおなじく、増大していることに注意してください。
"""


#############################################################################


"""
t分布とは？
（正規分布のレクチャーを先に見ることをおすすめします）
                                                                _
確率変数 x が、平均 μ 、標準偏差 σ の正規分布に従うとき、 x の N 個の平均 X は、
平均 μ 、標準偏差 σ / √N の正規分布に従います。これは、以下の様な新しい変数 z を導入して、
    _
z = X − μ / σ / √N


z が標準正規分布（平均0、標準偏差1）に従うと言い換えることが出来ます。

しかし、母集団の平均 μ や標準偏差 σ が分かっていることは稀なので、実際には、
これらを推定量で代用します。平均値はそのまま計算すれば良いですが、
分散の不偏推定量は、以下の式で求められます。

               N       _
σ̂^2 = 1 / N−1  ∑ (xi − X)^2
              i=1

ここで、あらたな変数 t を導入してみます
    _
t = X − μ / σ̂ / √N


先ほどの z とよく似ていますが、このtは特にNが小さい（一般的には30未満）とき正規分布に
従いません。では、どんな分布に従うかというと、 ν=N−1として、以下の様な分布に従います。
                     __
f(t) = Γ(v+1 / 2) / √vπ * Γ(v / 2) * (1 + t^2 / v)^−(v+1 / 2)


ただし:

Γ(n) = (n−1)!

これはガンマ関数と呼ばれる関数です。

NN が大きくなると、この分布は正規分布に漸近します。ですから、t分布はNが小さいときに、
標本の平均が従う分布と考えることができます。  νν は、t分布の自由度と呼ばれ、
この値が決まれば分布が決まります。また、発見者ゴセットの最初の論文のペンネームから、
スチューデント分布とよばれることもあります。

Pythonでt分布を扱ってみましょう。
"""


# x軸の数字を用意します。
x = np.linspace(-5, 5, 100)

# 自由度3のt分布
rv = t(3)

# 確率密度関数（PDF）を書きます。
plt.plot(x, rv.pdf(x))


"""
以下のサイトも参考になります。

1.) https://ja.wikipedia.org/wiki/T%E5%88%86%E5%B8%83

2.) http://www012.upp.so-net.ne.jp/doi/biostat/CT39/distribution.pdf

(英語） 3.) https://en.wikipedia.org/wiki/Student%27s_t-distribution

"""

"""
仮説検定
仮説検定（Hypothesis testing）は、統計量を使って、ある仮説が正しいかどうかを検討する方法です。

仮説検定のためのいくつかのステップを示します。厳密にこのステップに従う必要はありません。

1.) データの収集
2.) 前提条件
3.) 仮説（Hypothesis）
4.) 検定のための統計量（Test Statistic）
5.) 統計量の分布
6.) 意思決定のためのルール
7.) P値（p-values）

Step 1: データの収集
手元にデータがないと仮説検定を始められませんので、まずはデータをそろえます。

Step 2: 前提条件
データが従う分布など、仮説検定のための前提条件を検討します。

Step 3: 仮説
仮説には、2種類あります。帰無仮説（The Null Hypothesis） (Hoと書きます) と対立仮説
（Alternative Hypothesis） (HA)です。

例を使って説明します。

とあるレストランのお客さんのデータが手元にあって、このお客さんの平均年齢が30歳ではないことを
確かめたいとします。仮説は、以下の様に設定します。

Ho:μ=30

対立仮説は、次のようになります：
HA:μ≠30


仮説検定をして、帰無仮説（Ho)が棄却（reject）されると、代わりに対立仮説が採用されるので、
平均年齢が30歳ではないという仮説が正しいと証明されたことになるわけです。

もちろん、仮説の設定の仕方は変えられます。例えば、帰無仮説を、お客さんの平均年齢が、
30歳より大きいとすれば、対立仮説をお客さんの年齢が30歳より小さいとすることができます。
これは、後ほど図を使ってもう一度説明します。

Step 4: 検定統計量
適切な統計量を選びます。たとえば、正規分布を使うなら、次のようなzスコアが便利です。
    _
z = x−μo / (σ/√n)


推定された標準偏差を使って、t分布を使うこともできます。
    _
t = x−μo / (s/√n)

Step 5: 統計量の分布
統計量に応じた分布を選択します。

Step 6: 決定のためのルール
有意水準αを決めます。統計的な検定は、白か黒かをはっきり決められるものではありません。
ある一定の有意水準を定めて、その範囲内では自信があるという話にすぎません。αは、
経験的に5％や1％という数字が採用されることが多いようです。ここでは、5％を採用します。
つまり、95％の自信をもって、帰無仮説を棄却するということになります。
"""

url = 'http://images.flatworldknowledge.com/shafer/shafer-fig08_004.jpg'
Image(url, height=400, width=600)

"""

分布と有意水準で、帰無仮説を棄却するかどうかを、どのように決めるのかを説明します。

図は、2つのタイプの片側検定（One-Tail Test）と両側検定（Two-Tail Test）を示しています。 αの値に注意してください。

統計的検定には、判断を間違える可能性が常にあります。それぞれに名前が付いています。
"""

url = 'http://www.personal.ceu.hu/students/08/Olga_Etchevskaia/images/errors.jpg'
Image(url, height=200, width=300)

"""
第一種の過誤（TypeI error）は、偽陽性（False positive）とも呼ばれます。仮説を誤って棄却する可能性です。
第二種の過誤（TypeII error）は、偽陰性（Flase negative）とも呼ばれます。仮説を誤って受け入れてしまう可能性です。

Step 7: P値の計算
分布を使えば、統計量から、P値（P value）を計算できます。P値が有意水準を下回れば、
仮説を棄却できますし、この値が小さければ小さいほど、そこに自信が持てます。

例題
正規分布を使った仮説検定の例をみてみましょう。

とあるファストフードチェーンで働いているとしましょう。社長は顧客の平均年齢が30歳だと信じています。
しかし、現場の感覚では、それは違うような気がしており、そのことを統計を使って示してみます。

Ho:μ=30

HA:μ≠30


帰無仮説と対立仮説で、すべての事象をカバーしている必要があります。

Step 1: データを集める
調べたところ、お客さん10人の平均年齢が、27歳だということがわかりました。

Step 2: 前提条件
お店に来るお客さんの年齢の分布が、正規分布になるとしましょう。また、分散が20であるという知識も
得たとします。標準偏差は、この平方根です。

σ=√20


と、このような仮定を置きましたが、実際の問題では、母集団の分布やパラメータが分かっていることは
稀です。（いまは、例題なので、ひとまず話を進めます）

Step 3: 仮説
先ほど設定した仮説です。
Ho:μ=30

HA:μ≠30

Step 4: 検定統計量
Zスコアを計算します。
    _
z = x−μo / (σ/√n)


z = 27−30 / √20 / √10 = −2.12

Step 5: 分布
正規分布が使えます。

Step 6: ルール
有意水準は5％にします。つまり、95％の自信をもって、帰無仮説を棄却するということです。

結論
分布をみてみましょう。仮説を棄却できることがわかります。
"""


url = 'http://www.duncanwil.co.uk/norm_files/image056.jpg'
Image(url, height=200, width=300)

ss.norm.cdf(2.12,0,1)


p = 1 - ss.norm.cdf(2.12,0,1)
print(p)


"""

P値
となるので、P値は0.017(1.7%)になります。 やはり、現場の感覚が正しいようです。

信頼区間
次の式で、信頼区間（confidence interval）を計算できます。
_     _
x ± zσx

95％信頼区間を計算すると、

27 ± 1.96∗(√20 / √10)


つまり、
27±2.77


具体的には、24.23〜29.77となりますが、ここに30が含まれません。これは有意水準5％で帰無仮説を棄却したのと同じ計算です。

重要なところは、信頼区間の計算に分散が含まれているところです。分散が大きいと、信頼区間が大きくなります。
"""


###############################################################################
"""
カイ二乗の値
このレクチャーでは、カイ二乗の値について説明します。

100回コインを投げると、50回表が出て、50回裏がでます。もちろん、
いつもちょうど50回ずつになるわけではないので、実際に観測された値が、ありえるズレなのか、
どうかを統計的に検討できると便利です。

こんなときに使われるのが、カイ二乗分布です。カイは、ギリシャ文字のχです。

Event	Event1,	Event2,	Event3,	...	Event k
観測値（Observed Frequency）	o1 , o2 , o3 , ... , ok
予測される値（Expected Frequency）e1, e2, e3, ..., ek

例えば、あとで出てくる例では、2つのサイコロの目合計値が考えられます。
合計値が2になるのは、1/36なので、72回サイコロを投げれば、2回くらいというのが、予測される値という分けです。

カイ二乗値は、観測と予測のズレを足し合わせたイメージです。
χ2 = {(o1−e1)^2 / e1} + {(o2−e2)^2 / e2} + ... + {(ok−ek)^2 / ek}


書き方の問題ですが:
      k
χ^2 = ∑j = (oj−ej)^2 / ej
     j=1

カイ二乗分布
（少し厳密さに欠けますが）このχ2の値が従うのが、自由度kのχ二乗分布です。

自由度kが大きくなると、ピークがだんだん右にずれるのが分かると思います。
"""

url='https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/Chi-square_distributionPDF.png/1280px-Chi-square_distributionPDF.png'

Image(url)

"""
カイ二乗適合度検定（The Chi Square Test for Goodness of Fit）
この分布を使ってできる検定が、カイ二乗検定です。

計算はscipyがやってくれますので、まずは次のような例題を考えてみましょう。

あなたは、カジノで使われているサイコロが、いかさまではないか？と疑っています。これを、カイ二乗検定で確かめてみましょう。

500回のサイコロの2つの合計値を記録したものが、次の表です。

合計値	2	3	4	5	6	7	8	9	10	11	12
観測された回数	8	32	48	59	67	84	76	57	34	28	7
理想的なサイコロの合計値の頻度は次のようになるでしょう。

合計値	2	3	4	5	6	7	8	9	10	11	12
予想される頻度	1/36	2/36	3/36	4/36	5/36	6/36	5/36	4/36	3/36	2/36	1/36
500回という回数をかければ、よそうされる回数を計算できます。
"""

observed = [8,32,48,59,67,84,76,57,34,28,7]
roll_sum = sum(observed)
roll_sum



# 予想される頻度です。
freq = [1,2,3,4,5,6,5,4,3,2,1]

# Python2では、1.0としてください。
possible_rolls = 1/36

freq = [possible_rolls*dice for dice in freq]

freq


expected = [roll_sum*f for f in freq]
expected

chisq,p = stats.chisquare(observed,expected)

print('カイ二乗統計量= {:0.2f}'.format(chisq))
print('P値 = {:0.2f}'.format(p))

"""
stats.chisquareは、統計量とP値を同時に返してくれます。

P値がだいぶ高いので、サイコロはいかさまではなさそうです。
"""

###########################################################################
"""

ベイズの定理（Bayes Theorem）
このレクチャーでは、例を交えながら、ペイズの定理の基本的な内容を紹介します。

Overview
ベイズの定理は、条件付き確率を使って、次のように表現できます。

P(A|B) = P(B|A) * P(A) / P(B)


ここで、P(A|B) は、Bが起こったという条件のもとで、Aが起こる確率です。

ベイズの定理の真髄は、等号の左右で、 P(A|B) と P(B|A) が入れ替わっているところにあります。
これを例を通じて実感してみることにしましょう。

クッキー問題
ボールが2つあって、それぞれにクッキーが40個入っています。

ボール1には、バニラクッキーが30個、チョコレートクッキーが10個
ボール2には、バニラとチョコレートが20個ずつ
目を閉じて、どちらかのボールから、クッキーを1つ取り出しました。このクッキーがバニラだったとき、ボール1を選んだ確率は？

Bをバニラクッキーを選ぶという事象という意味でV、Aをボール1を選ぶ事象としてB1と書くことにします。

P(B1|V) = P(V|B1) * P(B1) / P(V)


文字を入れ替えただけですが、左辺は、バニラクッキーが選ばれたという条件のもとで、
ボールが1番だった確率を表現しているので、求めたいものに他なりません。右辺のパーツをすべて計算出来れば、答えが出ます。

P(V|B1)  ボール1を選んだ時に、バニラクッキーがでる確率  30/40
P(B1)  ボール1を選ぶ確率  1/2
P(V)  バニラクッキーを選ぶ確率  50/80
全部まとめると、

P(B1|V) = 3/5


となります。
"""
